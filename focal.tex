\section{Application: Finding Focal Methods}
\label{sec:focal}

We anticipate that one useful application of mock detection is to
improve the detection of focal methods in test cases, or as Ghafari et
al~\cite{ghafari15:_autom} call them, focal methods under test
(F-MUTs). In this section, we will discuss some approaches to finding
focal methods, and describe how our analysis can facilitate this search.

Ghafari's approach is the one that is most amenable to our work.
Their approach is applicable to tests for classes that implement
stateful objects, and assume that each test has at least one focal
method, seen as a call to a mutator method for the class under test.
The last such call is the focal method. However, their approach can
only work on tests of mutator methods.  Purely-functional methods, for
instance, are beyond the scope of their approach.

Another approach is name-based, as seen in the methods2test
dataset~\cite{tufano2020unit}.  This approach uses two heuristics: 1)
the name of the test matches the name of the focal method; or, 2) the
test calls a unique method in the focal class. Rompaey and
Demeyer~\cite{rompaey09:_estab_traceab_links_unit_test} explore the
name-based approach along with simply using the last method called
(not necessarily a mutator) as the focal method.  Ghafari points out
that these heuristics have significant limitations, especially when a
test case implements several sub-scenarios.

We discuss precision and recall issues. 

Include text from thesis 5.1 here.

\begin{table*}
	\centering
	\caption{Comparison of \% of test cases with reported focal methods by the two automated focal method detection algorithms.}
	\vspace*{.5em}
	\resizebox{\textwidth}{!}{\begin{tabular}{lrrrrrlrrrr} \toprule
		\multicolumn{5}{c}{Ghafari's algorithm} & & \multicolumn{5}{c}{methods2test}\\
		\cmidrule{1-5} \cmidrule{7-11}
		\thead{Benchmark} & \thead{Source Code \\ KLoC} & \thead{Reported \\ Focal Methods} & \thead{Test Cases} & \thead{\% of test cases \\ with focal \\ methods detected} &  & \thead{Benchmark} & \thead{Source Code \\ KLoC} & \thead{Reported \\ Focal Methods} & \thead{Test Cases} & \thead{\% of test cases \\ with focal \\ methods detected} \\ 
		\cmidrule{1-5} \cmidrule{7-11}
		
		commons-email-1.3.3 & 8.78 & 90  & 130 &  69\%  &  &    goja-0.1.14/goja-core  & 11.52 & 27  & 80 &  34\% \\
		PureMVC-1.0.8 & 19.46 & 34  & 43 &  79\%  &  &  mock-socket-0.9.0    & 1.09  & 4  & 34 &  12\%      \\
		XStream-1.4.4 & 54.93 & 513  & 968 &  53\%   &  &  project-sunbird-4.3.0/sunbird-lms-service   & 45.36 & 310  & 984 &  31\%   \\
		JGAP-3.4.4  & 73.96 & 1015  & 1390 &  73\%  &  &   optiq-0.8/core    & 93.94  & 26  & 1346 &  2\%   \\
		\bottomrule
		Geometric Mean &   &  &  &  68\% &   &  &  &  &  &  12\% 
	\end{tabular}}
	\label{tab:focal-method-algorithm-comparison}
\end{table*}
