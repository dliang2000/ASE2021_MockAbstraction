\begin{abstract}
	Unit testing is a widely used tool in modern software development processes. A well-known issue in writing tests is handling dependencies: creating usable objects for dependencies is often complicated. Developers must therefore often introduce mock objects to stand in for dependencies during testing. 

	We believe that the static analysis of test suites, alongside the systems under test, can enable developers to better characterize the behaviours of existing test suites, thus guiding further test suite analysis and manipulation. However, because mock objects are created using reflection, they confound existing static analysis techniques. At present, it is impossible to statically distinguish methods invoked on mock objects from methods invoked on real objects. Static analysis tools therefore currently cannot determine which dependencies' methods are actually tested, versus mock methods being called.

	In this paper, we introduce MockDetector, a technique to identify mock objects and pinpoint method invocations on mock objects. We built two different implementations of our analysis. The first implementation is a Soot-based imperative dataflow analysis, whereas the second implementation is a Doop-based declarative analysis. Both analyses handle common Java mock libraries' APIs for creating mock objects and propagate this information through test cases. Following our observations of tests in the wild, we have added special-case support for arrays and collections holding mock objects. On our suite of 8 open-source benchmarks, our imperative dataflow analysis approach reported 2,042 invocations on mock objects, whereas our declative dataflow approach reported 2,124 invocations on mock objects, out of a total number of 63,011 method invocations in test suites; across benchmarks, mock invocations accounted for a range from 0\% to 16.4\% of the total invocations. Removing confounding mock invocations from consideration as focal methods can improve the precision of focal method analysis, a key prerequisite to further analysis of test cases. %Both implementations have reported the same number of intra-procedural mock invocations on 4 out of the 8 open source benchmarks analyzed. 
	
	% results part to be updated
\end{abstract}
